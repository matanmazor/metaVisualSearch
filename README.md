# Prospective search time estimates reveal the strengths and limits of internal models of visual search | [*Journal of Experimental Psychology: General*, 2023](https://matanmazor.github.io/files/papers/mazor2023prospective.pdf)

Matan Mazor 👁️👁️, Max Siegel 👁️👁️ & Josh Tenenbaum 👁️👁️


![Experimental design, Exp. 1 and 2](https://github.com/matanmazor/metaVisualSearch/blob/master/docs/figures/methods1.png)

## Paper and analysis Scripts

[The full paper](https://matanmazor.github.io/files/papers/mazor2023prospective.pdf) can be fully reproduced from experimental data by knitting [The Rmarkdown file](https://github.com/matanmazor/metaVisualSearch/blob/master/docs/MVS.rmd).

## Experiment demos

[Experiment 1 (color and shape)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment1/)

[Experiment 2 (color and orientation)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment3/)

[Experiment 3 (Alphabet of the Magi)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment2/)

[Experiment 4 (Futurama Alphabet)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment4/)

[Experiment 5 (Visual search asymmetries)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment5/)

[Experiment 6 (Target-distractor similarity)](https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment6/)

Note: experiments in the data and experiments subdirectories are presented in the order in which they were run, with 1 and 2 being the two exploratory experiments, and 3 and 4 the pre-registered ones. In the paper we group exploratory experiments with their pre-registered extensions, such that Experiment 3 is presented as Experiment 2, and Experiment 3 is presented as Experiment 2.
